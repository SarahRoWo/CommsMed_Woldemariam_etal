{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotype Networks: Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# statistics\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "from scipy.stats.mstats import kruskalwallis\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# display dataframes\n",
    "from IPython.display import display\n",
    "\n",
    "# For graph title\n",
    "import re as re_title\n",
    "\n",
    "from math import log10, log2\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import py4cytoscape as p4c\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "np.set_printoptions(threshold=500)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_title(networkmetric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    __________\n",
    "    networkmetric : str\n",
    "        Network metric of interest\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    graph_title : str\n",
    "        Network metric with words separated for visualization\n",
    "    \"\"\"\n",
    "     \n",
    "    word_list = re_title.findall('[A-Z][^A-Z]*', networkmetric)\n",
    "    graph_title = ''\n",
    "    for word in word_list:\n",
    "        if word != word_list[-1]:\n",
    "            graph_title = graph_title + word + ' '\n",
    "        else:\n",
    "            graph_title = graph_title + word\n",
    "    \n",
    "    return graph_title           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there's a cytoscape connection\n",
    "# Cytoscape needs to be open to communicate with it via python\n",
    "p4c.cytoscape_ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 'phenotype' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagkeys = ['phenotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i setup_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "total_ad = 1688 #Total MatchIt patients with AD\n",
    "total_con = total_ad * 2 #Total MatchIt control patients\n",
    "cutoff = .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients with Alzheimer's (AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the diagnosis\n",
    "ad_diag_all = pd.read_csv('Diagnoses/phecode_diagnoses/ad_diagnoses.csv')\n",
    "\n",
    "# add column that indicates order icd10_chapter\n",
    "# NOTE: icd10_chapter ROUGHLY corresponds to icd-10 chapters, and some chapters are not included\n",
    "ad_diag_all['chp_order'] = ad_diag_all['icd10_chapter'].apply(ICDname_order)\n",
    "\n",
    "# Only keep diagnoses mapped to phecodes that are organized into ICD-10 inspired chapters\n",
    "ad_diag = ad_diag_all[~ad_diag_all['icd10_chapter'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_demo = pd.read_csv('Demographics/ad_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_diag = ad_diag.merge(ad_demo[['person_id', 'UCSFDerivedRaceEthnicity_Clean']], \n",
    "                        how='left', \n",
    "                        left_on='person_id', \n",
    "                        right_on='person_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only keep AD patients from MatchIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get person_ids for MatchIt Alzheimer's and Control patients\n",
    "ad_MatchIt = pd.read_csv('Demographics/RE_MI_ad_demo.csv')\n",
    "con_MatchIt = pd.read_csv('Demographics/RE_MI_con_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_diag = ad_diag[ad_diag['person_id'].isin(ad_MatchIt['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_diag_count = countPtsDiagnosis_Dict(ad_diag, total_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of patients stratified by race/ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_diag['UCSFDerivedRaceEthnicity_Clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numread = dict()\n",
    "\n",
    "for re in ad_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    numread[re] = ad_diag[ad_diag['UCSFDerivedRaceEthnicity_Clean'] == re][['person_id',\n",
    "                                                                            'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the diagnosis\n",
    "con_diag_all = pd.read_csv('Diagnoses/phecode_diagnoses/con_diagnoses.csv')\n",
    "\n",
    "# cond column that indicates order icd10_chapter\n",
    "# NOTE: icd10_chapter ROUGHLY corresponds to icd-10 chapters, and some chapters are not included\n",
    "con_diag_all['chp_order'] = con_diag_all['icd10_chapter'].apply(ICDname_order)\n",
    "\n",
    "# Only keep diagnoses mapped to phecodes that are organized into ICD-10 inspired chapters\n",
    "con_diag = con_diag_all[~con_diag_all['icd10_chapter'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag_all['person_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some patients without diagnoses lost when filtering for diagnoses mapped to phecodes\n",
    "# that have ICD-10 inspired chapters; will add them back in after adding demographic data\n",
    "con_diag['person_id'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_demo = pd.read_csv('Demographics/con_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge con_demo info to retain the remaining patients:\n",
    "con_diag = con_demo['person_id'].to_frame().merge(con_diag,\n",
    "                                                  how='left',\n",
    "                                                  on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have the smae number patients as con_diag_all['person_id'].nunique()\n",
    "con_diag['person_id'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only keep control patients from MatchIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get person_ids for MatchIt Control patients\n",
    "con_MatchIt = pd.read_csv('Demographics/RE_MI_con_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag = con_diag.merge(con_demo[['person_id', 'UCSFDerivedRaceEthnicity_Clean']], \n",
    "                          how='left', \n",
    "                          left_on='person_id', \n",
    "                          right_on='person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag = con_diag[con_diag['person_id'].isin(con_MatchIt['person_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag_count = countPtsDiagnosis_Dict(con_diag, total_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of patients stratified by race/ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag['UCSFDerivedRaceEthnicity_Clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrecon = dict()\n",
    "\n",
    "for re in con_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    numrecon[re] = con_diag[con_diag['UCSFDerivedRaceEthnicity_Clean'] == re][['person_id',\n",
    "                                                                               'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrecon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AD graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph\n",
    "AD_Graph = nx.Graph()\n",
    "# Add nodes to graph\n",
    "AD_nodes = ad_diag_count[n][n]\n",
    "AD_Graph.add_nodes_from(AD_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each disease, get AD/control distribution and unique patients\n",
    "print('Count number of patients per node...')\n",
    "diagtemp = ad_diag[['person_id',n,'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table where index is phenotype\n",
    "# for each phenotype is dict of # pts with that phenotype stratified by \n",
    "# race/ethnicity; person_id is total # pts with that phenotype\n",
    "diagtemp = pd.pivot_table(diagtemp, \n",
    "                          values=['person_id', 'UCSFDerivedRaceEthnicity_Clean'], \n",
    "                          index=n,\n",
    "                          aggfunc={'person_id' : lambda x: len(x.unique()), \n",
    "                                   'UCSFDerivedRaceEthnicity_Clean' : lambda x: dict(x.value_counts())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagtemp = diagtemp.sort_values('person_id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr = diagtemp[diagtemp.index.isin(AD_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add race/ethnicity information\n",
    "print('Set race/ethnicity as Attributes...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for re in ad_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    AD_node_attr[re] = AD_node_attr['UCSFDerivedRaceEthnicity_Clean'].apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re])\n",
    "    AD_node_attr['p'+re] = AD_node_attr['UCSFDerivedRaceEthnicity_Clean']\\\n",
    "                           .apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re]*100/numread[re])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace percent columns with first letter(s) of each race/ethnicity\n",
    "# Replace identified race and ethnicity columns to match UC-wide analysis\n",
    "AD_node_attr = AD_node_attr.rename({'pAsian' : 'pA',\n",
    "                                    'pBlack or African American' : 'pB',\n",
    "                                    'pLatinx' : 'pL',\n",
    "                                    'pWhite or Caucasian' : 'pW', \n",
    "                                    'Black or African American' : 'Black',\n",
    "                                    'Latinx' : 'Latine',\n",
    "                                    'White or Caucasian' : 'White'},\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr = AD_node_attr.drop('UCSFDerivedRaceEthnicity_Clean', axis=1)\n",
    "AD_node_attr = AD_node_attr.rename(columns={'person_id' : 'PtCount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge in icd10_chapter information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_diag_pheno = ad_diag[['phenotype', 'icd10_chapter']].drop_duplicates().set_index('phenotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad_diag_pheno.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adding icd10_chapter information...')\n",
    "AD_node_attr = AD_node_attr.merge(ad_diag_pheno, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save phenotypes \n",
    "AD_node_attr.index.to_frame().to_csv('Tables/AD_ntwrk_phenotypes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_node_attr = AD_node_attr.to_dict(orient='index') # Make the columns into a dictionary for node attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(AD_Graph, AD_node_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create all edges...')\n",
    "\n",
    "# make a dataframe of edges\n",
    "diagtemp = ad_diag[['person_id',n,'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates()\n",
    "diagtemp = diagtemp[diagtemp[n].isin(AD_nodes)]\n",
    "grouped = diagtemp.groupby('person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edges = []\n",
    "for k, pt in tqdm(list(grouped)):\n",
    "    # n choose k, where n is number of phenotypes (pt[n].sort_values()), and r is k:\n",
    "    #combo_list = list(itertools.combinations(pt[n], r=2)); modified below so phenotypes are sorted for patients\n",
    "    combo_list = list(itertools.combinations(pt[n].sort_values(), r=2))\n",
    "    combo_list = [(item,) for item in combo_list]\n",
    "    combo_df = pd.DataFrame(combo_list, columns=[n+'Combo']).drop_duplicates()\n",
    "    df_len = combo_df.shape[0]\n",
    "    combo_df['person_id'] = pt['person_id'].values[0]\n",
    "    combo_df['UCSFDerivedRaceEthnicity_Clean'] = pt['UCSFDerivedRaceEthnicity_Clean'].values[0]\n",
    "    AD_edges.append(combo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edges[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edges = pd.concat(AD_edges).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edges.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to graph\n",
    "AD_Graph.add_edges_from(AD_edges[n+'Combo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of patient for each edge.\n",
    "# May need to wait a few hours\n",
    "diagtemp = AD_edges\n",
    "diagtemp = pd.pivot_table(diagtemp, \n",
    "                          values=['person_id','UCSFDerivedRaceEthnicity_Clean'], \n",
    "                          index=n+'Combo',\n",
    "                          aggfunc={'person_id': lambda x: len(x.unique()), \n",
    "                                   'UCSFDerivedRaceEthnicity_Clean': lambda x: dict(x.value_counts())})\n",
    "\n",
    "print('sorting...')\n",
    "diagtemp = diagtemp.sort_values('person_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Add edge attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagtemp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edge_attr = diagtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for re in ad_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    AD_edge_attr[re] = AD_edge_attr['UCSFDerivedRaceEthnicity_Clean'].apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re])\n",
    "    AD_edge_attr['p'+str(re)] = AD_edge_attr['UCSFDerivedRaceEthnicity_Clean']\\\n",
    "                              .apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re]*100/numread[re])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_edge_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace percent columns with first letter(s) of each race/ethnicity\n",
    "AD_edge_attr = AD_edge_attr.rename({'pAsian' : 'pA',\n",
    "                                    'pBlack or African American' : 'pB',\n",
    "                                    'pLatinx' : 'pL',\n",
    "                                    'pWhite or Caucasian' : 'pW', \n",
    "                                    'Black or African American' : 'Black',\n",
    "                                    'Latinx' : 'Latine',\n",
    "                                    'White or Caucasian' : 'White'},\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AD_edge_attr = AD_edge_attr.drop('UCSFDerivedRaceEthnicity_Clean', axis=1)\n",
    "AD_edge_attr = AD_edge_attr.rename(columns={'person_id' : 'PtCount'})\n",
    "\n",
    "# Make dictionary\n",
    "AD_edge_attr = AD_edge_attr.to_dict(orient='index')\n",
    "nx.set_edge_attributes(AD_Graph, AD_edge_attr)\n",
    "\n",
    "print(nx.info(AD_Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Save file\n",
    "if os.path.isdir('Network_Analysis'):\n",
    "    if os.path.isdir('Network_Analysis/ADCon_phe'):\n",
    "        nx.write_graphml(AD_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_AD_ADCon.graphml')\n",
    "    else:\n",
    "        os.mkdir('Network_Analysis/ADCon_phe')\n",
    "        nx.write_graphml(AD_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_AD_ADCon.graphml')\n",
    "else:\n",
    "    os.mkdir('Network_Analysis')\n",
    "    os.mkdir('Network_Analysis/ADCon_phe')\n",
    "    nx.write_graphml(AD_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_AD_ADCon.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph\n",
    "con_Graph = nx.Graph()\n",
    "# Add nodes to graph\n",
    "con_nodes = con_diag_count[n][n]\n",
    "con_Graph.add_nodes_from(con_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each disease, get AD/control distribution and unique patients\n",
    "print('Count number of patients per node...')\n",
    "diagtemp = con_diag[['person_id',n,'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table where index is phenotype\n",
    "# for each phenotype is dict of # pts with that phenotype stratified by \n",
    "# race/ethnicity; person_id is total # pts with that phenotype\n",
    "diagtemp = pd.pivot_table(diagtemp, \n",
    "                          values=['person_id', 'UCSFDerivedRaceEthnicity_Clean'], \n",
    "                          index=n,\n",
    "                          aggfunc={'person_id' : lambda x: len(x.unique()), \n",
    "                                   'UCSFDerivedRaceEthnicity_Clean' : lambda x: dict(x.value_counts())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagtemp = diagtemp.sort_values('person_id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr = diagtemp[diagtemp.index.isin(con_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add race/ethnicity information\n",
    "print('Set race/ethnicity as Attributes...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for re in con_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    con_node_attr[re] = con_node_attr['UCSFDerivedRaceEthnicity_Clean'].apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re])\n",
    "    con_node_attr['p'+re] = con_node_attr['UCSFDerivedRaceEthnicity_Clean']\\\n",
    "                           .apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re]*100/numrecon[re])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace percent columns with first letter(s) of each race/ethnicity\n",
    "con_node_attr = con_node_attr.rename({'pAsian' : 'pA',\n",
    "                                    'pBlack or African American' : 'pB',\n",
    "                                    'pLatinx' : 'pL',\n",
    "                                    'pWhite or Caucasian' : 'pW', \n",
    "                                    'Black or African American' : 'Black',\n",
    "                                    'Latinx' : 'Latine',\n",
    "                                    'White or Caucasian' : 'White'},\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr = con_node_attr.drop('UCSFDerivedRaceEthnicity_Clean', axis=1)\n",
    "con_node_attr = con_node_attr.rename(columns={'person_id' : 'PtCount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge in icd10_chapter information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_diag_pheno = con_diag[['phenotype', 'icd10_chapter']].drop_duplicates().set_index('phenotype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adding icd10_chapter information...')\n",
    "con_node_attr = con_node_attr.merge(con_diag_pheno, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr.index.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save phenotypes \n",
    "con_node_attr.index.to_frame().to_csv('Tables/con_ntwrk_phenotypes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_node_attr = con_node_attr.to_dict(orient='index') # Make the columns into a dictionary for node attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(con_Graph, con_node_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create all edges...')\n",
    "\n",
    "# make a dataframe of edges\n",
    "diagtemp = con_diag[['person_id',n,'UCSFDerivedRaceEthnicity_Clean']].drop_duplicates()\n",
    "diagtemp = diagtemp[diagtemp[n].isin(con_nodes)]\n",
    "grouped = diagtemp.groupby('person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edges = []\n",
    "for k, pt in tqdm(list(grouped)):\n",
    "    # n choose k, where n is number of phenotypes (pt[n].sort_values()), and r is k:\n",
    "    #combo_list = list(itertools.combinations(pt[n], r=2)); modified below so phenotypes are sorted for patients\n",
    "    combo_list = list(itertools.combinations(pt[n].sort_values(), r=2))\n",
    "    combo_list = [(item,) for item in combo_list]\n",
    "    combo_df = pd.DataFrame(combo_list, columns=[n+'Combo']).drop_duplicates()\n",
    "    df_len = combo_df.shape[0]\n",
    "    combo_df['person_id'] = pt['person_id'].values[0]\n",
    "    combo_df['UCSFDerivedRaceEthnicity_Clean'] = pt['UCSFDerivedRaceEthnicity_Clean'].values[0]\n",
    "    con_edges.append(combo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2049 out of 3376 patients have phenotypes associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edges[2].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edges = pd.concat(con_edges).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edges.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to graph\n",
    "con_Graph.add_edges_from(con_edges[n+'Combo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of patient for each edge.\n",
    "# Need to wait a few hours\n",
    "diagtemp = con_edges\n",
    "diagtemp = pd.pivot_table(diagtemp, \n",
    "                          values=['person_id','UCSFDerivedRaceEthnicity_Clean'], \n",
    "                          index=n+'Combo',\n",
    "                          aggfunc={'person_id': lambda x: len(x.unique()), \n",
    "                                   'UCSFDerivedRaceEthnicity_Clean': lambda x: dict(x.value_counts())})\n",
    "\n",
    "print('sorting...')\n",
    "diagtemp = diagtemp.sort_values('person_id', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Add edge attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edge_attr = diagtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for re in con_diag['UCSFDerivedRaceEthnicity_Clean'].unique():\n",
    "    con_edge_attr[re] = con_edge_attr['UCSFDerivedRaceEthnicity_Clean'].apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re])\n",
    "    con_edge_attr['p'+str(re)] = con_edge_attr['UCSFDerivedRaceEthnicity_Clean']\\\n",
    "                              .apply(lambda lst: 0 if (re not in list(lst.keys())) else lst[re]*100/numrecon[re])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_edge_attr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace percent columns with first letter(s) of each race/ethnicity\n",
    "con_edge_attr = con_edge_attr.rename({'pAsian' : 'pA',\n",
    "                                    'pBlack or African American' : 'pB',\n",
    "                                    'pLatinx' : 'pL',\n",
    "                                    'pWhite or Caucasian' : 'pW', \n",
    "                                    'Black or African American' : 'Black',\n",
    "                                    'Latinx' : 'Latine',\n",
    "                                    'White or Caucasian' : 'White'},\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_edge_attr = con_edge_attr.drop('UCSFDerivedRaceEthnicity_Clean', axis=1)\n",
    "con_edge_attr = con_edge_attr.rename(columns={'person_id' : 'PtCount'})\n",
    "\n",
    "# Make dictionary\n",
    "con_edge_attr = con_edge_attr.to_dict(orient='index')\n",
    "nx.set_edge_attributes(con_Graph, con_edge_attr)\n",
    "\n",
    "print(nx.info(con_Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(con_edge_attr).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Save file\n",
    "if os.path.isdir('Network_Analysis'):\n",
    "    if os.path.isdir('Network_Analysis/ADCon_phe'):\n",
    "        nx.write_graphml(con_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_con_ADCon.graphml')\n",
    "    else:\n",
    "        os.mkdir('Network_Analysis/ADCon_phe')\n",
    "        nx.write_graphml(con_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_con_ADCon.graphml')\n",
    "else:\n",
    "    os.mkdir('Network_Analysis')\n",
    "    os.mkdir('Network_Analysis/ADCon_phe')\n",
    "    nx.write_graphml(con_Graph,'Network_Analysis/ADCon_phe/'+n+'graph_con_ADCon.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make race/ethnicity stratified AD graphs, where patients within each race/ethnicity share 5% of nodes and 5% of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_cutoff = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pA - percent Asian\n",
    "# pB - percent Black\n",
    "# pL - percent Latine\n",
    "# pW - percent White\n",
    "pct_re = ['pA', 'pB', 'pL', 'pW']\n",
    "ad_re = ['Asian_AD', 'Black_AD', 'Latine_AD', 'White_AD']\n",
    "con_re = ['Asian_con', 'Black_con', 'Latine_con', 'White_con']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_Graph.name = 'phenotype'\n",
    "con_Graph.name = 'phenotype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nx.info(AD_Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nx.info(con_Graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCSF_networks = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AD graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pct, label in zip(pct_re, ad_re):\n",
    "    selected_nodes = [n for n,v in AD_Graph.nodes(data=True) if v[pct] > graph_cutoff]\n",
    "    AD_Graph_x = AD_Graph.subgraph(selected_nodes).copy()\n",
    "    \n",
    "    for u,v,e in AD_Graph.edges(data=True):\n",
    "        if pct not in e:\n",
    "            if AD_Graph_x.has_edge(*(u,v)): \n",
    "                AD_Graph_x.remove_edge(*(u,v))\n",
    "        elif e[pct] <= graph_cutoff:\n",
    "            if AD_Graph_x.has_edge(*(u,v)): \n",
    "                AD_Graph_x.remove_edge(*(u,v))\n",
    "    \n",
    "    AD_Graph_x.name = label + '_phenotype'\n",
    "    print('before singletons removed:\\n', nx.info(AD_Graph_x), '\\n')\n",
    "    \n",
    "    # Remove singletons\n",
    "    AD_Graph_x.remove_nodes_from(list(nx.isolates(AD_Graph_x)))\n",
    "    print('after singletons removed:\\n', nx.info(AD_Graph_x), '\\n')\n",
    "    \n",
    "    # Save file\n",
    "    nx.write_graphml(AD_Graph_x,'Network_Analysis/ADCon_phe/'+n+'_'+label+'_'+str(graph_cutoff)+'.graphml')\n",
    "    \n",
    "    # Create network in Cytoscape\n",
    "    p4c.create_network_from_networkx(AD_Graph_x, title=label+'_'+str(graph_cutoff))\n",
    "    \n",
    "    # Add info to UCSF networks dictionary\n",
    "    UCSF_networks[label+'_'+str(graph_cutoff)] = p4c.get_network_suid(title=label+'_'+str(graph_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pct, label in zip(pct_re, con_re):\n",
    "    selected_nodes = [n for n,v in con_Graph.nodes(data=True) if v[pct] > graph_cutoff]\n",
    "    con_Graph_x = con_Graph.subgraph(selected_nodes).copy()\n",
    "    \n",
    "    for u,v,e in con_Graph.edges(data=True):\n",
    "        if pct not in e:\n",
    "            if con_Graph_x.has_edge(*(u,v)): \n",
    "                con_Graph_x.remove_edge(*(u,v))\n",
    "        elif e[pct] <= graph_cutoff:\n",
    "            if con_Graph_x.has_edge(*(u,v)): \n",
    "                con_Graph_x.remove_edge(*(u,v))\n",
    "    \n",
    "    con_Graph_x.name = label + '_phenotype'\n",
    "    print('before singletons removed:\\n', nx.info(con_Graph_x), '\\n')\n",
    "    \n",
    "    # Remove singletons\n",
    "    con_Graph_x.remove_nodes_from(list(nx.isolates(con_Graph_x)))\n",
    "    print('after singletons removed:\\n', nx.info(con_Graph_x), '\\n')\n",
    "    \n",
    "    # Save file\n",
    "    nx.write_graphml(con_Graph_x,'Network_Analysis/ADCon_phe/'+n+'_'+label+'_'+str(graph_cutoff)+'.graphml')\n",
    "    \n",
    "    # Create network in Cytoscape\n",
    "    p4c.create_network_from_networkx(con_Graph_x, title=label+'_'+str(graph_cutoff))\n",
    "    \n",
    "    # Add info to UCSF networks dictionary\n",
    "    UCSF_networks[label+'_'+str(graph_cutoff)] = p4c.get_network_suid(title=label+'_'+str(graph_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UCSF_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary network statistics\n",
    "ntwrk_summ_stats = dict()\n",
    "\n",
    "for network, SUID in UCSF_networks.items():\n",
    "    p4c.set_current_network(network=network)\n",
    "    ntwrk_summ_stats[network] = p4c.analyze_network()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ntwrk_summ_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics\n",
    "pd.DataFrame(ntwrk_summ_stats).transpose().sort_index().to_csv('Network_Analysis\\\\ADCon_phe\\\\summ_stats_'+str(graph_cutoff)+'.csv',\n",
    "                                                               index_label='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare AD networks with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_metrics = ['AverageShortestPathLength',\n",
    "                   'ClusteringCoefficient',\n",
    "                   'ClosenessCentrality',\n",
    "                   'Eccentricity',\n",
    "                   'Stress',\n",
    "                   'Degree',\n",
    "                   'BetweennessCentrality',\n",
    "                   'NeighborhoodConnectivity',\n",
    "                   'Radiality',\n",
    "                   'TopologicalCoefficient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node tables\n",
    "network_metric_values = dict()\n",
    "\n",
    "for network, SUID in UCSF_networks.items():\n",
    "    network_metric_values[network] = p4c.get_table_columns(table='node',  \n",
    "                                                           namespace='default', \n",
    "                                                           network=network, \n",
    "                                                           base_url='http://127.0.0.1:1234/v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in network_metric_values:\n",
    "    print(network_metric_values[network].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save node tables\n",
    "if os.path.isdir('Network_Analysis/ADCon_phe/node_tables'):\n",
    "    for network in network_metric_values:\n",
    "        pd.DataFrame(network_metric_values[network]).to_csv('Network_Analysis/ADCon_phe/node_tables/'+network+'_node_table.csv')\n",
    "else:\n",
    "    os.mkdir('Network_Analysis/ADCon_phe/node_tables')\n",
    "    for network in network_metric_values:\n",
    "        pd.DataFrame(network_metric_values[network]).to_csv('Network_Analysis/ADCon_phe/node_tables/'+network+'_node_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing AD networks with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5,2, figsize=(25,20))\n",
    "i = 0 # row\n",
    "j = 0 # column\n",
    "for metric in network_metrics:\n",
    "    A_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Asian_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    B_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Black_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    L_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Latine_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    W_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='White_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    \n",
    "    # Kruskal Wallis\n",
    "    stat, pval = kruskalwallis(A_AD, B_AD, L_AD, W_AD)\n",
    "    \n",
    "    # Add metric distribution to subplot\n",
    "    if j < 2:\n",
    "        axs[i,j].hist([A_AD, B_AD, L_AD, W_AD], color=['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3'])\n",
    "        axs[i,j].set_title(graph_title(metric), fontsize=18, fontweight='bold')\n",
    "        axs[i,j].set_ylabel('\\n \\n')\n",
    "        axs[i,j].tick_params(axis='both', which='both', labelsize=18)\n",
    "        if pval < 0.05:\n",
    "            # Added this after seeing distributions\n",
    "            if metric in ['ClosenessCentrality',\n",
    "                          'Stress',\n",
    "                          'Degree',\n",
    "                          'BetweennessCentrality',\n",
    "                          'NumberOfUndirectedEdges']:\n",
    "                axs[i,j].text(0.9, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "            else:\n",
    "                axs[i,j].text(0.1, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "        j += 1\n",
    "    else:\n",
    "        i += 1\n",
    "        j = 0\n",
    "        axs[i,j].hist([A_AD, B_AD, L_AD, W_AD], color=['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3'])\n",
    "        axs[i,j].set_title(graph_title(metric), fontsize=18, fontweight='bold')\n",
    "        axs[i,j].set_ylabel('\\n \\n')\n",
    "        axs[i,j].tick_params(axis='both', which='both', labelsize=18)\n",
    "        if pval < 0.05:\n",
    "            # Added this after seeing distributions\n",
    "            if metric in ['ClosenessCentrality',\n",
    "                          'Stress',\n",
    "                          'Degree',\n",
    "                          'BetweennessCentrality',\n",
    "                          'NumberOfUndirectedEdges']:\n",
    "                axs[i,j].text(0.9, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "            else:\n",
    "                axs[i,j].text(0.1, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "        j += 1     \n",
    "    \n",
    "    if pval < 0.05:\n",
    "        sig = 'significantly different'\n",
    "    else:\n",
    "        sig = 'not significantly different'\n",
    "    \n",
    "    print(metric + \" for AD patients' comparison is {}; statistic is {} and p-value is {}.\".format(sig,\n",
    "                                                                                                   stat,\n",
    "                                                                                                   pval))\n",
    "    print('\\n')\n",
    "    \n",
    "fig.legend(['Asian', 'Black', 'Latine', 'White'], \n",
    "           loc='upper right',\n",
    "           bbox_to_anchor=(1, 1.1),\n",
    "           fontsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "if os.path.isdir('Figures/Network_Analysis'):\n",
    "    plt.savefig('Figures/Network_Analysis/SuppFig_5.pdf', bbox_inches='tight')\n",
    "else:\n",
    "    os.mkdir('Figures/Network_Analysis')\n",
    "    plt.savefig('Figures/Network_Analysis/SuppFig_5.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dunn's test results for patients with AD to derive test statistics using R package `dunn.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(base_dir+'\\\\Tables\\\\R_Dunn'):\n",
    "    os.mkdir(base_dir+'\\\\Tables\\\\R_Dunn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in network_metrics:\n",
    "    \n",
    "    if not os.path.isdir(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric):\n",
    "        os.mkdir(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric)\n",
    "                         \n",
    "                         \n",
    "    \n",
    "    A_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Asian_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_frame()\n",
    "    A_AD = A_AD.reset_index(drop=True)\n",
    "    \n",
    "    A_AD.to_csv(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric + '\\\\A_AD_' + metric +'.csv')\n",
    "    \n",
    "    B_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Black_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric]\n",
    "    B_AD = B_AD.reset_index(drop=True)\n",
    "    \n",
    "    B_AD.to_csv(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric + '\\\\B_AD_' + metric +'.csv')\n",
    "    \n",
    "    L_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Latine_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric]\n",
    "    L_AD = L_AD.reset_index(drop=True)\n",
    "    \n",
    "    L_AD.to_csv(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric + '\\\\L_AD_' + metric +'.csv')\n",
    "    \n",
    "    W_AD = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='White_AD_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric]\n",
    "    W_AD = W_AD.reset_index(drop=True)\n",
    "    \n",
    "    W_AD.to_csv(base_dir + '\\\\Tables\\\\R_Dunn\\\\' + metric + '\\\\W_AD_' + metric +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing control networks with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5,2, figsize=(25,20))\n",
    "i = 0 # row\n",
    "j = 0 # column\n",
    "for metric in network_metrics:\n",
    "    A_con = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Asian_con_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    B_con = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Black_con_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    L_con = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='Latine_con_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    W_con = p4c.get_table_columns(table='node', \n",
    "                                 columns=metric, \n",
    "                                 namespace='default', \n",
    "                                 network='White_con_'+str(graph_cutoff), \n",
    "                                 base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "    \n",
    "    # Kruskal Wallis\n",
    "    stat, pval = kruskalwallis(A_con, B_con, L_con, W_con)\n",
    "    \n",
    "    # Add metric distribution to subplot\n",
    "    if j < 2:\n",
    "        axs[i,j].hist([A_con, B_con, L_con, W_con], color=['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3'])\n",
    "        axs[i,j].set_title(graph_title(metric), fontsize=18, fontweight='bold')\n",
    "        axs[i,j].set_ylabel('\\n \\n')\n",
    "        axs[i,j].tick_params(axis='both', which='both', labelsize=18)\n",
    "        if pval < 0.05:\n",
    "            # Added this after seeing distributions\n",
    "            if metric in ['ClosenessCentrality',\n",
    "                          'Stress',\n",
    "                          'Degree',\n",
    "                          'BetweennessCentrality',\n",
    "                          'NumberOfUndirectedEdges',\n",
    "                          'TopologicalCoefficient']:\n",
    "                axs[i,j].text(0.9, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "            else:\n",
    "                axs[i,j].text(0.1, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "        j += 1\n",
    "    else:\n",
    "        i += 1\n",
    "        j = 0\n",
    "        axs[i,j].hist([A_con, B_con, L_con, W_con], color=['#66C2A5', '#FC8D62', '#8DA0CB', '#E78AC3'])\n",
    "        axs[i,j].set_title(graph_title(metric), fontsize=18, fontweight='bold')\n",
    "        axs[i,j].set_ylabel('\\n \\n')\n",
    "        axs[i,j].tick_params(axis='both', which='both', labelsize=18)\n",
    "        if pval < 0.05:\n",
    "            # Added this after seeing distributions\n",
    "            if metric in ['ClosenessCentrality',\n",
    "                          'Stress',\n",
    "                          'Degree',\n",
    "                          'BetweennessCentrality',\n",
    "                          'NumberOfUndirectedEdges',\n",
    "                          'TopologicalCoefficient']:\n",
    "                print(metric)\n",
    "                axs[i,j].text(0.9, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "            else:\n",
    "                axs[i,j].text(0.1, \n",
    "                              0.9, \n",
    "                              'p-value < 0.05', \n",
    "                              horizontalalignment='center', \n",
    "                              verticalalignment='center',\n",
    "                              transform=axs[i,j].transAxes, fontsize=16)\n",
    "        j += 1     \n",
    "    \n",
    "    if pval < 0.05:\n",
    "        sig = 'significantly different'\n",
    "    else:\n",
    "        sig = 'not significantly different'\n",
    "\n",
    "        \n",
    "    print(metric + \" for control patients' comparison is {}; statistic is {} and p-value is {}.\".format(sig,\n",
    "                                                                                                   stat,\n",
    "                                                                                                   pval))\n",
    "    print('\\n')\n",
    "\n",
    "fig.legend(['Asian', 'Black', 'Latine', 'White'], \n",
    "           loc='upper right',\n",
    "           bbox_to_anchor=(1, 1.1),\n",
    "           fontsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "\n",
    "if os.path.isdir('Figures/Network_Analysis/'):\n",
    "    plt.savefig('Figures/Network_Analysis/SuppFig_6.pdf', bbox_inches='tight')\n",
    "else:\n",
    "    os.mkdir('Figures/Network_Analysis/')\n",
    "    plt.savefig('Figures/Network_Analysis/SuppFig_6.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare race/ethnicity-stratified AD and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_con_comp = [['Asian_AD_'+str(graph_cutoff), 'Asian_con_'+str(graph_cutoff)],\n",
    "               ['Black_AD_'+str(graph_cutoff), 'Black_con_'+str(graph_cutoff)],\n",
    "               ['Latine_AD_'+str(graph_cutoff), 'Latine_con_'+str(graph_cutoff)],\n",
    "               ['White_AD_'+str(graph_cutoff), 'White_con_'+str(graph_cutoff)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in AD_con_comp:\n",
    "    metric_results = dict()\n",
    "    for metric in network_metrics:\n",
    "        AD = p4c.get_table_columns(table='node', \n",
    "                                     columns=metric, \n",
    "                                     namespace='default', \n",
    "                                     network=comp[0], \n",
    "                                     base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "        con = p4c.get_table_columns(table='node', \n",
    "                                     columns=metric, \n",
    "                                     namespace='default', \n",
    "                                     network=comp[1], \n",
    "                                     base_url='http://127.0.0.1:1234/v1')[metric].to_list()\n",
    "        \n",
    "\n",
    "        # Mann Whitney U\n",
    "        stat, pval = mannwhitneyu(AD, con, alternative='two-sided')\n",
    "        if pval < 0.05:\n",
    "            sig = 'significantly different'\n",
    "        else:\n",
    "            sig = 'not significantly different'\n",
    "    \n",
    "        # Means for metrics\n",
    "        AD_mean = np.asarray(AD).mean()\n",
    "        con_mean = np.asarray(con).mean()\n",
    "    \n",
    "        metric_results[metric+'_pval'] = pval\n",
    "        metric_results[metric+'_AD_mean'] = AD_mean\n",
    "        metric_results[metric+'_con_mean'] = con_mean\n",
    "    \n",
    "        mann_whitney_results[comp[0]+'_vs_'+comp[1]] = metric_results\n",
    "    \n",
    "    \n",
    "        print(metric + \" for {} and {} comparison is {}; statistic is {} and p-value is {}.\".format(comp[0],\n",
    "                                                                                                comp[1],\n",
    "                                                                                                sig,\n",
    "                                                                                                stat,\n",
    "                                                                                                pval))\n",
    "        print('\\n')\n",
    "        print('Mean ' + metric +  ' for {} patients is {}; mean '.format(comp[0], round(AD_mean, 3)) + metric + \\\n",
    "              ' for {} patients is {}'.format(comp[1], round(con_mean, 3)))\n",
    "        print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "pd.DataFrame(mann_whitney_results).transpose().to_csv('Network_Analysis/ADCon_phe/AD_con_'+str(graph_cutoff)+'_mannwhitneyu.csv', \n",
    "                                                      index_label='comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at p values only:\n",
    "pd.DataFrame(mann_whitney_results).transpose().filter(like='_pval', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data: >25% cutoff (shared nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network, SUID in UCSF_networks.items():\n",
    "    p4c.set_current_network(network=network)\n",
    "    if 'Asian' in network:\n",
    "        column = 'pA'\n",
    "    elif 'Black' in network:\n",
    "        column = 'pB'\n",
    "    elif 'Latine' in network:\n",
    "        column = 'pL'\n",
    "    elif 'White' in network:\n",
    "        column = 'pW'\n",
    "    else:\n",
    "        print('p value column not found for network.')\n",
    "    p4c.create_column_filter(filter_name=network+'_10viz',\n",
    "                             column=column,\n",
    "                             criterion=25,\n",
    "                             predicate='GREATER_THAN',\n",
    "                             hide=True,\n",
    "                             type='nodes',\n",
    "                             network=network)\n",
    "    p4c.apply_filter(filter_name=network+'_10viz',\n",
    "                     hide=True,\n",
    "                     network=network)\n",
    "    p4c.set_visual_style(style_name='Sample1',\n",
    "                         network=network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network, SUID in UCSF_networks.items():\n",
    "    if 'con' in network:\n",
    "        print('Working on {}'.format(network))\n",
    "        p4c.set_current_network(network=network)\n",
    "        if 'Asian' in network:\n",
    "            column = 'pA'\n",
    "        elif 'Black' in network:\n",
    "            column = 'pB'\n",
    "        elif 'Latine' in network:\n",
    "            column = 'pL'\n",
    "        elif 'White' in network:\n",
    "            column = 'pW'\n",
    "        else:\n",
    "            print('p value column not found for network.')\n",
    "        p4c.create_column_filter(filter_name=network+'_10viz',\n",
    "                                 column=column,\n",
    "                                 criterion=25,\n",
    "                                 predicate='GREATER_THAN',\n",
    "                                 hide=True,\n",
    "                                 type='nodes',\n",
    "                                 network=network)\n",
    "        p4c.apply_filter(filter_name=network+'_10viz',\n",
    "                         hide=True,\n",
    "                         network=network)\n",
    "        p4c.set_visual_style(style_name='Sample1',\n",
    "                             network=network)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set node size to be based on number of patients with the condition for a given R&E category, and set node color to correspond to phecode category (icd10_chapter in node table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<a href='https://py4cytoscape.readthedocs.io/en/0.0.9/concepts.html#value-generators'>Link for implementation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of networks\n",
    "network_re_pct = dict()\n",
    "for network, SUID in UCSF_networks.items():\n",
    "    if 'Asian' in network:\n",
    "        network_re_pct[network] = 'pA'\n",
    "    elif 'Black' in network:\n",
    "        network_re_pct[network] = 'pB'\n",
    "    elif 'Latine' in network:\n",
    "        network_re_pct[network] = 'pL'\n",
    "    elif 'White' in network:\n",
    "        network_re_pct[network] = 'pW'\n",
    "    else:\n",
    "        print('Race/ethnicity category not in network; check conditionals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_re_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set node color mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get network with highest number of unique icd-10-inspired chapters\n",
    "# Ideally, all the chapters that could be included are included in this network - will double check\n",
    "icd10_network = 'None'\n",
    "icd10_network_chp = 'None'\n",
    "icd10_network_length = 0\n",
    "for network in p4c.get_network_list():\n",
    "    temp = len(p4c.get_table_columns(table='node',  \n",
    "                                     namespace='default', \n",
    "                                     columns='icd10_chapter',\n",
    "                                     network=network, \n",
    "                                     base_url='http://127.0.0.1:1234/v1')['icd10_chapter'].unique())\n",
    "    chp = p4c.get_table_columns(table='node',  \n",
    "                                namespace='default', \n",
    "                                columns='icd10_chapter',\n",
    "                                network=network, \n",
    "                                base_url='http://127.0.0.1:1234/v1')['icd10_chapter'].unique()\n",
    "    print('{} network has {} unique phecode chapters'.format(network, temp))\n",
    "    \n",
    "    if temp == icd10_network_length:\n",
    "        if len(set(chp) & icd10_network_chp) == icd10_network_length:\n",
    "            print('{} network has the same chapters as the network previously identified with the most chapters'.format(network))\n",
    "        else:\n",
    "            print('{} network does not have the same chapters as the network previously identified with the most chapters'.format(network))\n",
    "    if temp > icd10_network_length:\n",
    "        icd10_network_length = temp\n",
    "        icd10_network = network\n",
    "        print(chp)\n",
    "        icd10_network_chp = set(chp)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color_map = p4c.gen_node_color_map(table_column='icd10_chapter', \n",
    "                                        palette=p4c.palette_color_brewer_q_Set3(),\n",
    "                                        mapping_type='d', \n",
    "                                        network=icd10_network,\n",
    "                                        style_name='Sample1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in p4c.get_network_list():\n",
    "    print('Working on {}'.format(network))\n",
    "    p4c.set_current_network(network=network)\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_size_map = p4c.gen_node_size_map(table_column=network_re_pct[network], \n",
    "                                          mapping_type='c', \n",
    "                                          network=network, \n",
    "                                          style_name='Sample1')\n",
    "    \n",
    "    print(node_size_map['sizes'])\n",
    "    print('\\n')\n",
    "    # change sizes to wider range of values\n",
    "    '''\n",
    "    if 'AD' in network:\n",
    "        node_size_map['sizes'] = [10, 1995, 4000] # 10, 500, 900\n",
    "    elif 'con' in network:\n",
    "        node_size_map['sizes'] = [100, 200, 300]\n",
    "    '''\n",
    "    node_size_map['sizes'] = [100, 200 ,300]\n",
    "    p4c.set_node_size_mapping(**node_size_map)\n",
    "    p4c.set_node_font_size_mapping(**node_size_map)\n",
    "    \n",
    "    edge_width_map = p4c.gen_edge_width_map(table_column=network_re_pct[network], \n",
    "                                            mapping_type='c', \n",
    "                                            network=network, \n",
    "                                            style_name='Sample1')\n",
    "    # change width key to smaller values\n",
    "    # edge_width_map['widths'] = [3, 15, 75]\n",
    "    p4c.set_edge_line_width_mapping(**edge_width_map)\n",
    "    #p4c.set_edge_opacity_mapping(**p4c.gen_edge_opacity_map(table_column=network_re_pct[network], \n",
    "                                                             #mapping_type='c', \n",
    "                                                             #network=network, \n",
    "                                                             #style_name='Sample1'))\n",
    "    \n",
    "    p4c.set_node_color_mapping(**node_color_map)\n",
    "    p4c.layout_network(layout_name='circular', network=network)\n",
    "    p4c.style_bypasses.set_network_zoom_bypass(new_value=0.3, bypass=True, network=network)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in p4c.get_network_list():\n",
    "    p4c.style_bypasses.set_network_zoom_bypass(new_value=0.25, bypass=True, network=network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4c.set_edge_opacity_default(new_opacity=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4c.save_session('Ntwrk_Viz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in p4c.get_network_list():\n",
    "    print('Saving {} image'.format(network))\n",
    "    p4c.set_current_network(network=network)\n",
    "    p4c.export_image(filename=network+'.pdf', type='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
